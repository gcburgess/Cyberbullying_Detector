{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import pos_tag, FreqDist\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_colwidth = 300 # max width of a column\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/gburgess/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jigsaw_df = pd.read_csv('../data/jigsaw-unintended-bias-in-toxicity-classification/all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_toxic = (jigsaw_df['toxicity'] >= 0.5) | (jigsaw_df['severe_toxicity'] >= 0.1) | \\\n",
    "            (jigsaw_df['obscene'] >= 0.25) | (jigsaw_df['sexual_explicit'] >= 0.25) | \\\n",
    "            (jigsaw_df['identity_attack'] >= 0.25) | (jigsaw_df['insult'] >= 0.25) | \\\n",
    "            (jigsaw_df['threat'] >= 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1999516 entries, 0 to 1999515\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   id            1999516 non-null  int64 \n",
      " 1   comment_text  1999515 non-null  object\n",
      " 2   target        1999516 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 45.8+ MB\n"
     ]
    }
   ],
   "source": [
    "new_target_df = pd.DataFrame()\n",
    "new_target_df[['id', 'comment_text']] = jigsaw_df[['id', 'comment_text']].copy()\n",
    "new_target_df['target'] = (is_toxic).astype(int)\n",
    "new_target_df.info(show_counts=True, memory_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove single row with NaN in `comment_text` (probably there just for fun!)\n",
    "new_target_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del jigsaw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338409"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_target = (new_target_df['target'] == 1)\n",
    "num_targets = sum(is_target)\n",
    "num_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    338409\n",
       "0    338409\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_df = resample(new_target_df[ is_target ],\n",
    "                       replace=False,\n",
    "                       n_samples=num_targets,\n",
    "                       random_state=42)\n",
    "\n",
    "minority_df = resample(new_target_df[ ~is_target ],\n",
    "                       replace=False,\n",
    "                       n_samples=num_targets,\n",
    "                       random_state=42)\n",
    "\n",
    "train_df = pd.concat([majority_df, minority_df])\n",
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "X = train_df['comment_text']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    '''\n",
    "    Translate nltk POS to wordnet tags\n",
    "    '''\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')\n",
    "\n",
    "def word_processor(comment, stopword_list=sw):\n",
    "    # tokenize (simultaneously removes punctuation)\n",
    "    tokenizer = RegexpTokenizer(pattern=\"([a-zA-Z]+(?:'[a-z]+)?)\")\n",
    "    words = tokenizer.tokenize(comment)\n",
    "\n",
    "    # lowercase and remove stopwords\n",
    "    words = [word.lower() for word in words if word.lower() not in stopword_list]\n",
    "    \n",
    "    # lemmatize (accounting for part of speech)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word[0], get_wordnet_pos(word[1])) \n",
    "             for word in pos_tag(words)]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Int64Index: 507613 entries, 1483102 to 1422804\n",
      "Series name: comment_text\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "507613 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 507613 entries, 1483102 to 1422804\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   target        507613 non-null  int64 \n",
      " 1   comment_text  507613 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 11.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 5s, sys: 8.65 s, total: 13min 14s\n",
      "Wall time: 13min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['proc_text'] = list(map(word_processor, train_df['comment_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target comment before tokenizing:  Dead On Arrival......won't ever pass!\n",
      "Target comment after tokenizing : ['dead', 'arrival', 'ever', 'pas']\n",
      "\n",
      "Target comment before tokenizing:  Drain the swamp? Really?  Suckers!!!!\n",
      "Target comment after tokenizing : ['drain', 'swamp', 'really', 'sucker']\n",
      "\n",
      "Target comment before tokenizing:  I will confirm your statement.  I have worked with most of the employees that were put through hell by this government.  The thing that continues to bother me is that the lead investigator ended up being promoted and moved out of the ministry where she continues in an executive position with high pay but has no staff.  Everybody concerned that brought on this hell has ended up being protected by the liberals with promotions or nice severance packages.  Just remember when you vote in May on the type of government you want.\n",
      "Target comment after tokenizing : ['confirm', 'statement', 'work', 'employee', 'put', 'hell', 'government', 'thing', 'continue', 'bother', 'lead', 'investigator', 'end', 'promote', 'moved', 'ministry', 'continue', 'executive', 'position', 'high', 'pay', 'staff', 'everybody', 'concern', 'brought', 'hell', 'end', 'protect', 'liberal', 'promotion', 'nice', 'severance', 'package', 'remember', 'vote', 'may', 'type', 'government', 'want']\n",
      "\n",
      "Non-target comment before tokenizing:  You would think the Springfield Police have better things to do other than ticketing those drivers and passengers who donate. Where will the proposed $50 fine go? To help the unhoused in some way? To hear Springfield councilors talk about all the services they provide for the homeless is nothing but an attempt to put lipstick on the pig.\n",
      "\n",
      "Some supporters of the ordinance imagine that all donations go for drugs or alcohol.\n",
      "\n",
      "As adults, we know that some donations could possibly be used for these purposes but don't need the city to make that decision for us. Again, I note the privileged attitude that only those who are housed can self-medicate.\n",
      "\n",
      "I'd like business owners in Springfield to know that some of us Eugenians will no longer shop in Springfield.\n",
      "Non-target comment after tokenizing : ['would', 'think', 'springfield', 'police', 'well', 'thing', 'ticket', 'driver', 'passenger', 'donate', 'propose', 'fine', 'go', 'help', 'unhoused', 'way', 'hear', 'springfield', 'councilors', 'talk', 'service', 'provide', 'homeless', 'nothing', 'attempt', 'put', 'lipstick', 'pig', 'supporter', 'ordinance', 'imagine', 'donation', 'go', 'drug', 'alcohol', 'adult', 'know', 'donation', 'could', 'possibly', 'use', 'purpose', 'need', 'city', 'make', 'decision', 'u', 'note', 'privileged', 'attitude', 'house', 'self', 'medicate', \"i'd\", 'like', 'business', 'owner', 'springfield', 'know', 'u', 'eugenians', 'long', 'shop', 'springfield']\n",
      "\n",
      "Non-target comment before tokenizing:  I asked first.\n",
      "\n",
      "The point is that if we can't identify how a non-binary person is supposed to look, then it's not useful information on an ID card used to verify your identity.\n",
      "\n",
      "By contrast, we can generally identify people's sex just  by looking at their body size and shape, even if they're all wearing jeans and a T-shirt.\n",
      "Non-target comment after tokenizing : ['ask', 'first', 'point', \"can't\", 'identify', 'non', 'binary', 'person', 'suppose', 'look', 'useful', 'information', 'id', 'card', 'use', 'verify', 'identity', 'contrast', 'generally', 'identify', \"people's\", 'sex', 'look', 'body', 'size', 'shape', 'even', \"they're\", 'wear', 'jean', 'shirt']\n",
      "\n",
      "Non-target comment before tokenizing:  well if it's not a crime then hey give me a job I love to Sip and Grandpa's old cough syrup well I'm teaching the kids to do as I say not as I do. now hate me Islanders.\n",
      "Non-target comment after tokenizing : ['well', 'crime', 'hey', 'give', 'job', 'love', 'sip', \"grandpa's\", 'old', 'cough', 'syrup', 'well', \"i'm\", 'teach', 'kid', 'say', 'hate', 'islander']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "is_target = (train_df['target'] == 1)\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Target comment before tokenizing: \", train_df[is_target]['comment_text'].iloc[i])\n",
    "    print(\"Target comment after tokenizing :\", train_df[is_target]['proc_text'].iloc[i])\n",
    "    print()\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"Non-target comment before tokenizing: \", train_df[~is_target]['comment_text'].iloc[i])\n",
    "    print(\"Non-target comment after tokenizing :\", train_df[~is_target]['proc_text'].iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bully_train_df = train_df[is_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>proc_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1483102</th>\n",
       "      <td>1</td>\n",
       "      <td>Dead On Arrival......won't ever pass!</td>\n",
       "      <td>[dead, arrival, ever, pas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132094</th>\n",
       "      <td>1</td>\n",
       "      <td>Drain the swamp? Really?  Suckers!!!!</td>\n",
       "      <td>[drain, swamp, really, sucker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486986</th>\n",
       "      <td>1</td>\n",
       "      <td>I will confirm your statement.  I have worked with most of the employees that were put through hell by this government.  The thing that continues to bother me is that the lead investigator ended up being promoted and moved out of the ministry where she continues in an executive position with hig...</td>\n",
       "      <td>[confirm, statement, work, employee, put, hell, government, thing, continue, bother, lead, investigator, end, promote, moved, ministry, continue, executive, position, high, pay, staff, everybody, concern, brought, hell, end, protect, liberal, promotion, nice, severance, package, remember, vote, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351710</th>\n",
       "      <td>1</td>\n",
       "      <td>I suspect Bush's reticence to open his mouth has something to do with that old bit of folk wisdom about \"people in glass houses who've committed a slew of war crimes\" not throwing stones and all.  Besides, I think it's hard for Bush to string sentences together without Cheney's hand up his backs...</td>\n",
       "      <td>[suspect, bush's, reticence, open, mouth, something, old, bit, folk, wisdom, people, glass, house, who've, commit, slew, war, crime, throw, stone, besides, think, hard, bush, string, sentence, together, without, cheney's, hand, backside]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401223</th>\n",
       "      <td>1</td>\n",
       "      <td>Also if there is a catastrophe which we hope will not happen, but if it does federal aid will be very slow because Ige and Chin will make this a sanctuary state and it will be there fault for the slow aid we get, or the federal aid we get some of it could be cut off because of our sanctuary stat...</td>\n",
       "      <td>[also, catastrophe, hope, happen, federal, aid, slow, ige, chin, make, sanctuary, state, fault, slow, aid, get, federal, aid, get, could, cut, sanctuary, state, status, happen, blame, clown, two, state, mayor]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target  \\\n",
       "1483102       1   \n",
       "132094        1   \n",
       "1486986       1   \n",
       "1351710       1   \n",
       "401223        1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        comment_text  \\\n",
       "1483102                                                                                                                                                                                                                                                                        Dead On Arrival......won't ever pass!   \n",
       "132094                                                                                                                                                                                                                                                                         Drain the swamp? Really?  Suckers!!!!   \n",
       "1486986  I will confirm your statement.  I have worked with most of the employees that were put through hell by this government.  The thing that continues to bother me is that the lead investigator ended up being promoted and moved out of the ministry where she continues in an executive position with hig...   \n",
       "1351710  I suspect Bush's reticence to open his mouth has something to do with that old bit of folk wisdom about \"people in glass houses who've committed a slew of war crimes\" not throwing stones and all.  Besides, I think it's hard for Bush to string sentences together without Cheney's hand up his backs...   \n",
       "401223   Also if there is a catastrophe which we hope will not happen, but if it does federal aid will be very slow because Ige and Chin will make this a sanctuary state and it will be there fault for the slow aid we get, or the federal aid we get some of it could be cut off because of our sanctuary stat...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                           proc_text  \n",
       "1483102                                                                                                                                                                                                                                                                                   [dead, arrival, ever, pas]  \n",
       "132094                                                                                                                                                                                                                                                                                [drain, swamp, really, sucker]  \n",
       "1486986  [confirm, statement, work, employee, put, hell, government, thing, continue, bother, lead, investigator, end, promote, moved, ministry, continue, executive, position, high, pay, staff, everybody, concern, brought, hell, end, protect, liberal, promotion, nice, severance, package, remember, vote, ...  \n",
       "1351710                                                                [suspect, bush's, reticence, open, mouth, something, old, bit, folk, wisdom, people, glass, house, who've, commit, slew, war, crime, throw, stone, besides, think, hard, bush, string, sentence, together, without, cheney's, hand, backside]  \n",
       "401223                                                                                             [also, catastrophe, hope, happen, federal, aid, slow, ige, chin, make, sanctuary, state, fault, slow, aid, get, federal, aid, get, could, cut, sanctuary, state, status, happen, blame, clown, two, state, mayor]  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bully_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bully_corpus_list = sum(bully_train_df['proc_text'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bully_freq_dist = FreqDist(bully_corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bully_freq = pd.Series(dict(bully_freq_dist.most_common(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "bully_plot = sns.barplot(x=bully_freq.values, y=bully_freq.index, ax=ax)\n",
    "plt.savefig('../images/bully_FreqDist.jpg', transparent = False, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbully_train_df = train_df[~is_target]\n",
    "nonbully_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nonbully_corpus_list = sum(nonbully_train_df['proc_text'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nonbully_freq_dist = FreqDist(nonbully_corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "nonbully_plot = sns.barplot(x=nonbully_freq.values, y=nonbully_freq.index, ax=ax)\n",
    "plt.savefig('../images/nonbully_FreqDist.jpg', transparent = False, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(min_font_size=10, max_font_size=100, \n",
    "                      width=1000, height=1000).generate_from_frequencies(dict(bully_freq_dist))\n",
    "wordcloud.to_file(\"../images/bully_wordcloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(min_font_size=10, max_font_size=100, \n",
    "                      width=1000, height=1000,\n",
    "                      background_color='white').generate_from_frequencies(dict(nonbully_freq_dist))\n",
    "wordcloud.to_file(\"../images/nonbully_wordcloud.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp-env)",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
